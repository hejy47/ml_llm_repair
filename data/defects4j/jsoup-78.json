{"org.jsoup.helper.DataUtil.parseInputStream": {"buggy_content": "static Document parseInputStream(InputStream input, String charsetName, String baseUri, Parser parser) throws IOException {\n    if (// empty body\n    input == null)\n        return new Document(baseUri);\n    input = ConstrainableInputStream.wrap(input, bufferSize, 0);\n    Document doc = null;\n    boolean fullyRead = false;\n    // read the start of the stream and look for a BOM or meta charset\n    input.mark(bufferSize);\n    // -1 because we read one more to see if completed. First read is < buffer size, so can't be invalid.\n    ByteBuffer firstBytes = readToByteBuffer(input, firstReadBufferSize - 1);\n    fullyRead = input.read() == -1;\n    input.reset();\n    // look for BOM - overrides any other header or input\n    BomCharset bomCharset = detectCharsetFromBom(firstBytes);\n    if (bomCharset != null) {\n        charsetName = bomCharset.charset;\n        input.skip(bomCharset.offset);\n    }\n    if (charsetName == null) {\n        // determine from meta. safe first parse as UTF-8\n        String docData = Charset.forName(defaultCharset).decode(firstBytes).toString();\n        doc = parser.parseInput(docData, baseUri);\n        // look for <meta http-equiv=\"Content-Type\" content=\"text/html;charset=gb2312\"> or HTML5 <meta charset=\"gb2312\">\n        Elements metaElements = doc.select(\"meta[http-equiv=content-type], meta[charset]\");\n        // if not found, will keep utf-8 as best attempt\n        String foundCharset = null;\n        for (Element meta : metaElements) {\n            if (meta.hasAttr(\"http-equiv\"))\n                foundCharset = getCharsetFromContentType(meta.attr(\"content\"));\n            if (foundCharset == null && meta.hasAttr(\"charset\"))\n                foundCharset = meta.attr(\"charset\");\n            if (foundCharset != null)\n                break;\n        }\n        // look for <?xml encoding='ISO-8859-1'?>\n        if (foundCharset == null && doc.childNodeSize() > 0 && doc.childNode(0) instanceof XmlDeclaration) {\n            XmlDeclaration prolog = (XmlDeclaration) doc.childNode(0);\n            if (prolog.name().equals(\"xml\"))\n                foundCharset = prolog.attr(\"encoding\");\n        }\n        foundCharset = validateCharset(foundCharset);\n        if (foundCharset != null && !foundCharset.equalsIgnoreCase(defaultCharset)) {\n            // need to re-decode. (case insensitive check here to match how validate works)\n            foundCharset = foundCharset.trim().replaceAll(\"[\\\"']\", \"\");\n            charsetName = foundCharset;\n            doc = null;\n        } else if (!fullyRead) {\n            doc = null;\n        }\n    } else {\n        // specified by content type header (or by user on file load)\n        Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n    }\n    if (doc == null) {\n        if (charsetName == null)\n            charsetName = defaultCharset;\n        BufferedReader reader = new BufferedReader(new InputStreamReader(input, charsetName), bufferSize);\n        doc = parser.parseInput(reader, baseUri);\n        // io exception when parsing (not seen before because reading the stream as we go)\n        doc.outputSettings().charset(charsetName);\n    }\n    input.close();\n    return doc;\n}", "method_range": "93-157", "fault_locations": "150,151,152,153"}}