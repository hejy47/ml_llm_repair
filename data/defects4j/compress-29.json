{"org.apache.commons.compress.archivers.ArchiveStreamFactory.createArchiveOutputStream": {"buggy_content": "public ArchiveOutputStream createArchiveOutputStream(final String archiverName, final OutputStream out) throws ArchiveException {\n    if (archiverName == null) {\n        throw new IllegalArgumentException(\"Archivername must not be null.\");\n    }\n    if (out == null) {\n        throw new IllegalArgumentException(\"OutputStream must not be null.\");\n    }\n    if (AR.equalsIgnoreCase(archiverName)) {\n        return new ArArchiveOutputStream(out);\n    }\n    if (ZIP.equalsIgnoreCase(archiverName)) {\n        ZipArchiveOutputStream zip = new ZipArchiveOutputStream(out);\n        if (entryEncoding != null) {\n            zip.setEncoding(entryEncoding);\n        }\n        return zip;\n    }\n    if (TAR.equalsIgnoreCase(archiverName)) {\n        if (entryEncoding != null) {\n            return new TarArchiveOutputStream(out, entryEncoding);\n        } else {\n            return new TarArchiveOutputStream(out);\n        }\n    }\n    if (JAR.equalsIgnoreCase(archiverName)) {\n        return new JarArchiveOutputStream(out);\n    }\n    if (CPIO.equalsIgnoreCase(archiverName)) {\n        if (entryEncoding != null) {\n            return new CpioArchiveOutputStream(out, entryEncoding);\n        } else {\n            return new CpioArchiveOutputStream(out);\n        }\n    }\n    if (SEVEN_Z.equalsIgnoreCase(archiverName)) {\n        throw new StreamingNotSupportedException(SEVEN_Z);\n    }\n    throw new ArchiveException(\"Archiver: \" + archiverName + \" not found.\");\n}", "method_range": "269-310", "fault_locations": "296,297,298"}, "org.apache.commons.compress.archivers.ArchiveStreamFactory.createArchiveInputStream": {"buggy_content": "public ArchiveInputStream createArchiveInputStream(final InputStream in) throws ArchiveException {\n    if (in == null) {\n        throw new IllegalArgumentException(\"Stream must not be null.\");\n    }\n    if (!in.markSupported()) {\n        throw new IllegalArgumentException(\"Mark is not supported.\");\n    }\n    final byte[] signature = new byte[12];\n    in.mark(signature.length);\n    try {\n        int signatureLength = IOUtils.readFully(in, signature);\n        in.reset();\n        if (ZipArchiveInputStream.matches(signature, signatureLength)) {\n            if (entryEncoding != null) {\n                return new ZipArchiveInputStream(in, entryEncoding);\n            } else {\n                return new ZipArchiveInputStream(in);\n            }\n        } else if (JarArchiveInputStream.matches(signature, signatureLength)) {\n            if (entryEncoding != null) {\n                return new JarArchiveInputStream(in, entryEncoding);\n            } else {\n                return new JarArchiveInputStream(in);\n            }\n        } else if (ArArchiveInputStream.matches(signature, signatureLength)) {\n            return new ArArchiveInputStream(in);\n        } else if (CpioArchiveInputStream.matches(signature, signatureLength)) {\n            if (entryEncoding != null) {\n                return new CpioArchiveInputStream(in, entryEncoding);\n            } else {\n                return new CpioArchiveInputStream(in);\n            }\n        } else if (ArjArchiveInputStream.matches(signature, signatureLength)) {\n            return new ArjArchiveInputStream(in);\n        } else if (SevenZFile.matches(signature, signatureLength)) {\n            throw new StreamingNotSupportedException(SEVEN_Z);\n        }\n        // Dump needs a bigger buffer to check the signature;\n        final byte[] dumpsig = new byte[32];\n        in.mark(dumpsig.length);\n        signatureLength = IOUtils.readFully(in, dumpsig);\n        in.reset();\n        if (DumpArchiveInputStream.matches(dumpsig, signatureLength)) {\n            return new DumpArchiveInputStream(in, entryEncoding);\n        }\n        // Tar needs an even bigger buffer to check the signature; read the first block\n        final byte[] tarheader = new byte[512];\n        in.mark(tarheader.length);\n        signatureLength = IOUtils.readFully(in, tarheader);\n        in.reset();\n        if (TarArchiveInputStream.matches(tarheader, signatureLength)) {\n            return new TarArchiveInputStream(in, entryEncoding);\n        }\n        // COMPRESS-117 - improve auto-recognition\n        if (signatureLength >= 512) {\n            TarArchiveInputStream tais = null;\n            try {\n                tais = new TarArchiveInputStream(new ByteArrayInputStream(tarheader));\n                // COMPRESS-191 - verify the header checksum\n                if (tais.getNextTarEntry().isCheckSumOK()) {\n                    return new TarArchiveInputStream(in, encoding);\n                }\n            } catch (Exception e) {\n                // NOPMD\n                // can generate IllegalArgumentException as well\n                // as IOException\n                // autodetection, simply not a TAR\n                // ignored\n            } finally {\n                IOUtils.closeQuietly(tais);\n            }\n        }\n    } catch (IOException e) {\n        throw new ArchiveException(\"Could not use reset and mark operations.\", e);\n    }\n    throw new ArchiveException(\"No Archiver found for the stream signature\");\n}", "method_range": "324-405", "fault_locations": "359,360,361"}, "org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream.CpioArchiveInputStream": {"buggy_content": "public CpioArchiveInputStream(final InputStream in, int blockSize, String encoding) {\n    this.in = in;\n    this.blockSize = blockSize;\n    this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n}", "method_range": "152-156", "fault_locations": "154,155"}, "org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream.CpioArchiveOutputStream": {"buggy_content": "public CpioArchiveOutputStream(final OutputStream out, final short format, final int blockSize, final String encoding) {\n    this.out = out;\n    switch(format) {\n        case FORMAT_NEW:\n        case FORMAT_NEW_CRC:\n        case FORMAT_OLD_ASCII:\n        case FORMAT_OLD_BINARY:\n            break;\n        default:\n            throw new IllegalArgumentException(\"Unknown format: \" + format);\n    }\n    this.entryFormat = format;\n    this.blockSize = blockSize;\n    this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n}", "method_range": "147-163", "fault_locations": "161,162"}, "org.apache.commons.compress.archivers.dump.DumpArchiveInputStream.DumpArchiveInputStream": {"buggy_content": "public DumpArchiveInputStream(InputStream is, String encoding) throws ArchiveException {\n    this.raw = new TapeInputStream(is);\n    this.hasHitEOF = false;\n    this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n    try {\n        // read header, verify it's a dump archive.\n        byte[] headerBytes = raw.readRecord();\n        if (!DumpArchiveUtil.verify(headerBytes)) {\n            throw new UnrecognizedFormatException();\n        }\n        // get summary information\n        summary = new DumpArchiveSummary(headerBytes, this.zipEncoding);\n        // reset buffer with actual block size.\n        raw.resetBlockSize(summary.getNTRec(), summary.isCompressed());\n        // allocate our read buffer.\n        blockBuffer = new byte[4 * DumpArchiveConstants.TP_SIZE];\n        // skip past CLRI and BITS segments since we don't handle them yet.\n        readCLRI();\n        readBITS();\n    } catch (IOException ex) {\n        throw new ArchiveException(ex.getMessage(), ex);\n    }\n    // put in a dummy record for the root node.\n    Dirent root = new Dirent(2, 2, 4, \".\");\n    names.put(2, root);\n    // use priority based on queue to ensure parent directories are\n    // released first.\n    queue = new PriorityQueue<DumpArchiveEntry>(10, new Comparator<DumpArchiveEntry>() {\n\n        public int compare(DumpArchiveEntry p, DumpArchiveEntry q) {\n            if (p.getOriginalName() == null || q.getOriginalName() == null) {\n                return Integer.MAX_VALUE;\n            }\n            return p.getOriginalName().compareTo(q.getOriginalName());\n        }\n    });\n}", "method_range": "100-146", "fault_locations": "103,104"}, "org.apache.commons.compress.archivers.tar.TarArchiveInputStream.TarArchiveInputStream": {"buggy_content": "public TarArchiveInputStream(InputStream is, int blockSize, int recordSize, String encoding) {\n    this.is = is;\n    this.hasHitEOF = false;\n    this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n    this.recordSize = recordSize;\n    this.blockSize = blockSize;\n}", "method_range": "138-145", "fault_locations": "141,142"}, "org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.TarArchiveOutputStream": {"buggy_content": "public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize, String encoding) {\n    out = new CountingOutputStream(os);\n    this.zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n    this.assemLen = 0;\n    this.assemBuf = new byte[recordSize];\n    this.recordBuf = new byte[recordSize];\n    this.recordSize = recordSize;\n    this.recordsPerBlock = blockSize / recordSize;\n}", "method_range": "152-162", "fault_locations": "154,155"}, "org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.ZipArchiveInputStream": {"buggy_content": "public ZipArchiveInputStream(InputStream inputStream, String encoding, boolean useUnicodeExtraFields, boolean allowStoredEntriesWithDataDescriptor) {\n    zipEncoding = ZipEncodingHelper.getZipEncoding(encoding);\n    this.useUnicodeExtraFields = useUnicodeExtraFields;\n    in = new PushbackInputStream(inputStream, buf.capacity());\n    this.allowStoredEntriesWithDataDescriptor = allowStoredEntriesWithDataDescriptor;\n    // haven't read anything so far\n    buf.limit(0);\n}", "method_range": "180-191", "fault_locations": "183,184"}}