[{"output": "This function appears to be part of an optimization algorithm, which has multiple components and calls to other functions. In order to provide a fix, we would need more context such as what the line.search() function does or what the newPointAndDirection() function does.\n\nWithout that information, we cannot provide a meaningful fix for the entire function. However, we can identify one potential issue with the code. \n\nIn the while loop, there is a condition for stopping the optimization process: \n\n```\nstop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n```\n\nThis condition uses a tolerance check with relative and absolute thresholds, which are parameters in the optimization algorithm. However, it is recommended to use a convergence checker to determine when to stop the optimization rather than hardcoding a tolerance check in the code. \n\nTo fix this issue, we can replace the condition with the following code:\n\n```\nboolean stop = checker != null && checker.converged(iter, previous, current);\n```\n\nThis code checks whether a convergence checker is provided and uses it to determine whether to stop the optimization based on the iteration number, previous and current function values and other relevant information. \n\nOf course, this fix assumes that a proper convergence checker is available and configured for the optimization algorithm.", "diff": "", "finish_reason": "stop", "valid": false, "num": 17}, {"output": "@Override\nprotected PointValuePair doOptimize() {\n    checkParameters();\n    final GoalType goal = getGoalType();\n    final double[] guess = getStartPoint();\n    final int n = guess.length;\n    final double[][] direc = new double[n][n];\n    for (int i = 0; i < n; i++) {\n        direc[i][i] = 1;\n    }\n    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n    double[] x = guess;\n    double fVal = computeObjectiveValue(x);\n    double[] x1 = x.clone();\n    int iter = 0;\n    while (true) {\n        ++iter;\n        double fX = fVal;\n        double fX2 = 0;\n        double delta = 0;\n        int bigInd = 0;\n        double alphaMin = 0;\n        for (int i = 0; i < n; i++) {\n            final double[] d = MathArrays.copyOf(direc[i]);\n            fX2 = fVal;\n            final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n            fVal = optimum.getValue();\n            alphaMin = optimum.getPoint();\n            final double[][] result = newPointAndDirection(x, d, alphaMin);\n            x = result[0];\n            if ((fX2 - fVal) > delta) {\n                delta = fX2 - fVal;\n                bigInd = i;\n            }\n        }\n        // Default convergence check.\n        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n        final PointValuePair previous = new PointValuePair(x1, fX);\n        final PointValuePair current = new PointValuePair(x, fVal);\n        if (!stop) {\n            // User-defined stopping criteria.\n            if (checker != null) {\n                stop = checker.converged(iter, previous, current);\n            }\n        }\n        if (stop) {\n            if (goal == GoalType.MINIMIZE) {\n                return (fVal < fX) ? current : previous;\n            } else {\n                return (fVal > fX) ? current : previous;\n            }\n        }\n        final double[] d = new double[n];\n        final double[] x2 = new double[n];\n        for (int i = 0; i < n; i++) {\n            d[i] = x[i] - x1[i];\n            x2[i] = 2 * x[i] - x1[i];\n        }\n        x1 = x.clone();\n        fX2 = computeObjectiveValue(x2);\n        if (fX > fX2) {\n            double t = 2 * (fX + fX2 - 2 * fVal);\n            double temp = fX - fVal - delta;\n            t *= temp * temp;\n            temp = fX - fX2;\n            t -= delta * temp * temp;\n            if (t < 0.0) {\n                final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n                fVal = optimum.getValue();\n                alphaMin = optimum.getPoint();\n                final double[][] result = newPointAndDirection(x, d, alphaMin);\n                x = result[0];\n                final int lastInd = n - 1;\n                direc[bigInd] = direc[lastInd];\n                direc[lastInd] = result[1];\n            }\n        }\n    }\n}", "diff": "--- org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizer.java@doOptimize\n@@ -1,87 +1,78 @@\n @Override\n protected PointValuePair doOptimize() {\n+    checkParameters();\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n     final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n-    final double[] point = getStartPoint();\n-    final GoalType goal = getGoalType();\n-    final int n = point.length;\n-    double[] r = computeObjectiveGradient(point);\n-    if (goal == GoalType.MINIMIZE) {\n-        for (int i = 0; i < n; i++) {\n-            r[i] = -r[i];\n-        }\n-    }\n-    // Initial search direction.\n-    double[] steepestDescent = preconditioner.precondition(point, r);\n-    double[] searchDirection = steepestDescent.clone();\n-    double delta = 0;\n-    for (int i = 0; i < n; ++i) {\n-        delta += r[i] * searchDirection[i];\n-    }\n-    PointValuePair current = null;\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n     int iter = 0;\n-    int maxEval = getMaxEvaluations();\n     while (true) {\n         ++iter;\n-        final double objective = computeObjectiveValue(point);\n-        PointValuePair previous = current;\n-        current = new PointValuePair(point, objective);\n-        if (previous != null) {\n-            if (checker.converged(iter, previous, current)) {\n-                // We have found an optimum.\n-                return current;\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        // Find the optimal step in the search direction.\n-        final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);\n-        final double uB = findUpperBound(lsf, 0, initialStep);\n-        // XXX Last parameters is set to a value close to zero in order to\n-        // work around the divergence problem in the \"testCircleFitting\"\n-        // unit test (see MATH-439).\n-        final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);\n-        // Subtract used up evaluations.\n-        maxEval -= solver.getEvaluations();\n-        // Validate new point.\n-        for (int i = 0; i < point.length; ++i) {\n-            point[i] += step * searchDirection[i];\n-        }\n-        r = computeObjectiveGradient(point);\n-        if (goal == GoalType.MINIMIZE) {\n-            for (int i = 0; i < n; ++i) {\n-                r[i] = -r[i];\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n             }\n         }\n-        // Compute beta.\n-        final double deltaOld = delta;\n-        final double[] newSteepestDescent = preconditioner.precondition(point, r);\n-        delta = 0;\n-        for (int i = 0; i < n; ++i) {\n-            delta += r[i] * newSteepestDescent[i];\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n         }\n-        final double beta;\n-        switch(updateFormula) {\n-            case FLETCHER_REEVES:\n-                beta = delta / deltaOld;\n-                break;\n-            case POLAK_RIBIERE:\n-                double deltaMid = 0;\n-                for (int i = 0; i < r.length; ++i) {\n-                    deltaMid += r[i] * steepestDescent[i];\n-                }\n-                beta = (delta - deltaMid) / deltaOld;\n-                break;\n-            default:\n-                // Should never happen.\n-                throw new MathInternalError();\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n         }\n-        steepestDescent = newSteepestDescent;\n-        // Compute conjugate search direction.\n-        if (iter % n == 0 || beta < 0) {\n-            // Break conjugation: reset search direction.\n-            searchDirection = steepestDescent.clone();\n-        } else {\n-            // Compute new conjugate search direction.\n-            for (int i = 0; i < n; ++i) {\n-                searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n     }\n--- org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizer.java@doOptimize\n@@ -1,135 +1,79 @@\n @Override\n protected PointValuePair doOptimize() {\n-    // -------------------- Initialization --------------------------------\n-    isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n-    final FitnessFunction fitfun = new FitnessFunction();\n+    checkParameters();\n+    final GoalType goal = getGoalType();\n     final double[] guess = getStartPoint();\n-    // number of objective variables/problem dimension\n-    dimension = guess.length;\n-    initializeCMA(guess);\n-    iterations = 0;\n-    double bestValue = fitfun.value(guess);\n-    push(fitnessHistory, bestValue);\n-    PointValuePair optimum = new PointValuePair(getStartPoint(), isMinimize ? bestValue : -bestValue);\n-    PointValuePair lastResult = null;\n-    // -------------------- Generation Loop --------------------------------\n-    generationLoop: for (iterations = 1; iterations <= maxIterations; iterations++) {\n-        // Generate and evaluate lambda offspring\n-        final RealMatrix arz = randn1(dimension, lambda);\n-        final RealMatrix arx = zeros(dimension, lambda);\n-        final double[] fitness = new double[lambda];\n-        // generate random offspring\n-        for (int k = 0; k < lambda; k++) {\n-            RealMatrix arxk = null;\n-            for (int i = 0; i < checkFeasableCount + 1; i++) {\n-                if (diagonalOnly <= 0) {\n-                    arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k)).scalarMultiply(// m + sig * Normal(0,C)\n-                    sigma));\n-                } else {\n-                    arxk = xmean.add(times(diagD, arz.getColumnMatrix(k)).scalarMultiply(sigma));\n-                }\n-                if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {\n-                    break;\n-                }\n-                // regenerate random arguments for row\n-                arz.setColumn(k, randn(dimension));\n-            }\n-            copyColumn(arxk, 0, arx, k);\n-            try {\n-                // compute fitness\n-                fitness[k] = fitfun.value(arx.getColumn(k));\n-            } catch (TooManyEvaluationsException e) {\n-                break generationLoop;\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n+    int iter = 0;\n+    while (true) {\n+        ++iter;\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        // Sort by fitness and compute weighted mean into xmean\n-        final int[] arindex = sortedIndices(fitness);\n-        // Calculate new xmean, this is selection and recombination\n-        // for speed up of Eq. (2) and (3)\n-        final RealMatrix xold = xmean;\n-        final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n-        xmean = bestArx.multiply(weights);\n-        final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n-        final RealMatrix zmean = bestArz.multiply(weights);\n-        final boolean hsig = updateEvolutionPaths(zmean, xold);\n-        if (diagonalOnly <= 0) {\n-            updateCovariance(hsig, bestArx, arz, arindex, xold);\n-        } else {\n-            updateCovarianceDiagonalOnly(hsig, bestArz);\n-        }\n-        // Adapt step size sigma - Eq. (5)\n-        sigma *= Math.exp(Math.min(1, (normps / chiN - 1) * cs / damps));\n-        final double bestFitness = fitness[arindex[0]];\n-        final double worstFitness = fitness[arindex[arindex.length - 1]];\n-        if (bestValue > bestFitness) {\n-            bestValue = bestFitness;\n-            lastResult = optimum;\n-            optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)), isMinimize ? bestFitness : -bestFitness);\n-            if (getConvergenceChecker() != null && lastResult != null) {\n-                if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n-                    break generationLoop;\n-                }\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n             }\n         }\n-        // handle termination criteria\n-        // Break, if fitness is good enough\n-        if (stopFitness != 0) {\n-            // only if stopFitness is defined\n-            if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n-                break generationLoop;\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n             }\n         }\n-        final double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n-        final double[] pcCol = pc.getColumn(0);\n-        for (int i = 0; i < dimension; i++) {\n-            if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) {\n-                break;\n-            }\n-            if (i >= dimension - 1) {\n-                break generationLoop;\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n-        for (int i = 0; i < dimension; i++) {\n-            if (sigma * sqrtDiagC[i] > stopTolUpX) {\n-                break generationLoop;\n-            }\n-        }\n-        final double historyBest = min(fitnessHistory);\n-        final double historyWorst = max(fitnessHistory);\n-        if (iterations > 2 && Math.max(historyWorst, worstFitness) - Math.min(historyBest, bestFitness) < stopTolFun) {\n-            break generationLoop;\n-        }\n-        if (iterations > fitnessHistory.length && historyWorst - historyBest < stopTolHistFun) {\n-            break generationLoop;\n-        }\n-        // condition number of the covariance matrix exceeds 1e14\n-        if (max(diagD) / min(diagD) > 1e7) {\n-            break generationLoop;\n-        }\n-        // user defined termination\n-        if (getConvergenceChecker() != null) {\n-            final PointValuePair current = new PointValuePair(bestArx.getColumn(0), isMinimize ? bestFitness : -bestFitness);\n-            if (lastResult != null && getConvergenceChecker().converged(iterations, current, lastResult)) {\n-                break generationLoop;\n-            }\n-            lastResult = current;\n-        }\n-        // Adjust step size in case of equal function values (flat fitness)\n-        if (bestValue == fitness[arindex[(int) (0.1 + lambda / 4.)]]) {\n-            sigma = sigma * Math.exp(0.2 + cs / damps);\n-        }\n-        if (iterations > 2 && Math.max(historyWorst, bestFitness) - Math.min(historyBest, bestFitness) == 0) {\n-            sigma = sigma * Math.exp(0.2 + cs / damps);\n-        }\n-        // store best in history\n-        push(fitnessHistory, bestFitness);\n-        fitfun.setValueRange(worstFitness - bestFitness);\n-        if (generateStatistics) {\n-            statisticsSigmaHistory.add(sigma);\n-            statisticsFitnessHistory.add(bestFitness);\n-            statisticsMeanHistory.add(xmean.transpose());\n-            statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n-        }\n     }\n-    return optimum;\n }\n--- org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizer.java@doOptimize\n@@ -23,7 +23,7 @@\n         for (int i = 0; i < n; i++) {\n             final double[] d = MathArrays.copyOf(direc[i]);\n             fX2 = fVal;\n-            final UnivariatePointValuePair optimum = line.search(x, d);\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n             fVal = optimum.getValue();\n             alphaMin = optimum.getPoint();\n             final double[][] result = newPointAndDirection(x, d, alphaMin);\n@@ -65,7 +65,7 @@\n             temp = fX - fX2;\n             t -= delta * temp * temp;\n             if (t < 0.0) {\n-                final UnivariatePointValuePair optimum = line.search(x, d);\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n                 fVal = optimum.getValue();\n                 alphaMin = optimum.getPoint();\n                 final double[][] result = newPointAndDirection(x, d, alphaMin);\n--- org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizer.java@doOptimize\n@@ -1,44 +1,79 @@\n @Override\n protected PointValuePair doOptimize() {\n     checkParameters();\n-    // Indirect call to \"computeObjectiveValue\" in order to update the\n-    // evaluations counter.\n-    final MultivariateFunction evalFunc = new MultivariateFunction() {\n-\n-        public double value(double[] point) {\n-            return computeObjectiveValue(point);\n-        }\n-    };\n-    final boolean isMinim = getGoalType() == GoalType.MINIMIZE;\n-    final Comparator<PointValuePair> comparator = new Comparator<PointValuePair>() {\n-\n-        public int compare(final PointValuePair o1, final PointValuePair o2) {\n-            final double v1 = o1.getValue();\n-            final double v2 = o2.getValue();\n-            return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1);\n-        }\n-    };\n-    // Initialize search.\n-    simplex.build(getStartPoint());\n-    simplex.evaluate(evalFunc, comparator);\n-    PointValuePair[] previous = null;\n-    int iteration = 0;\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n     final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n+    int iter = 0;\n     while (true) {\n-        if (iteration > 0) {\n-            boolean converged = true;\n-            for (int i = 0; i < simplex.getSize(); i++) {\n-                PointValuePair prev = previous[i];\n-                converged = converged && checker.converged(iteration, prev, simplex.getPoint(i));\n-            }\n-            if (converged) {\n-                // We have found an optimum.\n-                return simplex.getPoint(0);\n+        ++iter;\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        // We still need to search.\n-        previous = simplex.getPoints();\n-        simplex.iterate(evalFunc, comparator);\n-        ++iteration;\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n+            }\n+        }\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n+        }\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n+            }\n+        }\n     }\n }\n--- org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizer.java@doOptimize\n@@ -1,76 +1,79 @@\n @Override\n-public PointVectorValuePair doOptimize() {\n+protected PointValuePair doOptimize() {\n     checkParameters();\n-    final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n-    // Computation will be useless without a checker (see \"for-loop\").\n-    if (checker == null) {\n-        throw new NullArgumentException();\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n     }\n-    final double[] targetValues = getTarget();\n-    // Number of observed data.\n-    final int nR = targetValues.length;\n-    final RealMatrix weightMatrix = getWeight();\n-    // Diagonal of the weight matrix.\n-    final double[] residualsWeights = new double[nR];\n-    for (int i = 0; i < nR; i++) {\n-        residualsWeights[i] = weightMatrix.getEntry(i, i);\n-    }\n-    final double[] currentPoint = getStartPoint();\n-    final int nC = currentPoint.length;\n-    // iterate until convergence is reached\n-    PointVectorValuePair current = null;\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n     int iter = 0;\n-    for (boolean converged = false; !converged; ) {\n+    while (true) {\n         ++iter;\n-        // evaluate the objective function and its jacobian\n-        PointVectorValuePair previous = current;\n-        // Value of the objective function at \"currentPoint\".\n-        final double[] currentObjective = computeObjectiveValue(currentPoint);\n-        final double[] currentResiduals = computeResiduals(currentObjective);\n-        final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint);\n-        current = new PointVectorValuePair(currentPoint, currentObjective);\n-        // build the linear problem\n-        final double[] b = new double[nC];\n-        final double[][] a = new double[nC][nC];\n-        for (int i = 0; i < nR; ++i) {\n-            final double[] grad = weightedJacobian.getRow(i);\n-            final double weight = residualsWeights[i];\n-            final double residual = currentResiduals[i];\n-            // compute the normal equation\n-            final double wr = weight * residual;\n-            for (int j = 0; j < nC; ++j) {\n-                b[j] += wr * grad[j];\n-            }\n-            // build the contribution matrix for measurement i\n-            for (int k = 0; k < nC; ++k) {\n-                double[] ak = a[k];\n-                double wgk = weight * grad[k];\n-                for (int l = 0; l < nC; ++l) {\n-                    ak[l] += wgk * grad[l];\n-                }\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        try {\n-            // solve the linearized least squares problem\n-            RealMatrix mA = new BlockRealMatrix(a);\n-            DecompositionSolver solver = useLU ? new LUDecomposition(mA).getSolver() : new QRDecomposition(mA).getSolver();\n-            final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray();\n-            // update the estimated parameters\n-            for (int i = 0; i < nC; ++i) {\n-                currentPoint[i] += dX[i];\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n             }\n-        } catch (SingularMatrixException e) {\n-            throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM);\n         }\n-        // Check convergence.\n-        if (previous != null) {\n-            converged = checker.converged(iter, previous, current);\n-            if (converged) {\n-                setCost(computeCost(currentResiduals));\n-                return current;\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n+        }\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n     }\n-    // Must never happen.\n-    throw new MathInternalError();\n }\n--- org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizer.java@doOptimize\n@@ -1,219 +1,78 @@\n @Override\n-protected PointVectorValuePair doOptimize() {\n+protected PointValuePair doOptimize() {\n     checkParameters();\n-    // Number of observed data.\n-    final int nR = getTarget().length;\n-    final double[] currentPoint = getStartPoint();\n-    // Number of parameters.\n-    final int nC = currentPoint.length;\n-    // arrays shared with the other private methods\n-    solvedCols = FastMath.min(nR, nC);\n-    diagR = new double[nC];\n-    jacNorm = new double[nC];\n-    beta = new double[nC];\n-    permutation = new int[nC];\n-    lmDir = new double[nC];\n-    // local point\n-    double delta = 0;\n-    double xNorm = 0;\n-    double[] diag = new double[nC];\n-    double[] oldX = new double[nC];\n-    double[] oldRes = new double[nR];\n-    double[] oldObj = new double[nR];\n-    double[] qtf = new double[nR];\n-    double[] work1 = new double[nC];\n-    double[] work2 = new double[nC];\n-    double[] work3 = new double[nC];\n-    final RealMatrix weightMatrixSqrt = getWeightSquareRoot();\n-    // Evaluate the function at the starting point and calculate its norm.\n-    double[] currentObjective = computeObjectiveValue(currentPoint);\n-    double[] currentResiduals = computeResiduals(currentObjective);\n-    PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);\n-    double currentCost = computeCost(currentResiduals);\n-    // Outer loop.\n-    lmPar = 0;\n-    boolean firstIteration = true;\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n     int iter = 0;\n-    final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n     while (true) {\n         ++iter;\n-        final PointVectorValuePair previous = current;\n-        // QR decomposition of the jacobian matrix\n-        qrDecomposition(computeWeightedJacobian(currentPoint));\n-        weightedResidual = weightMatrixSqrt.operate(currentResiduals);\n-        for (int i = 0; i < nR; i++) {\n-            qtf[i] = weightedResidual[i];\n-        }\n-        // compute Qt.res\n-        qTy(qtf);\n-        // now we don't need Q anymore,\n-        // so let jacobian contain the R matrix with its diagonal elements\n-        for (int k = 0; k < solvedCols; ++k) {\n-            int pk = permutation[k];\n-            weightedJacobian[k][pk] = diagR[pk];\n-        }\n-        if (firstIteration) {\n-            // scale the point according to the norms of the columns\n-            // of the initial jacobian\n-            xNorm = 0;\n-            for (int k = 0; k < nC; ++k) {\n-                double dk = jacNorm[k];\n-                if (dk == 0) {\n-                    dk = 1.0;\n-                }\n-                double xk = dk * currentPoint[k];\n-                xNorm += xk * xk;\n-                diag[k] = dk;\n-            }\n-            xNorm = FastMath.sqrt(xNorm);\n-            // initialize the step bound delta\n-            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n-        }\n-        // check orthogonality between function vector and jacobian columns\n-        double maxCosine = 0;\n-        if (currentCost != 0) {\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                double s = jacNorm[pj];\n-                if (s != 0) {\n-                    double sum = 0;\n-                    for (int i = 0; i <= j; ++i) {\n-                        sum += weightedJacobian[i][pj] * qtf[i];\n-                    }\n-                    maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));\n-                }\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        if (maxCosine <= orthoTolerance) {\n-            // Convergence has been reached.\n-            setCost(currentCost);\n-            return current;\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n+            }\n         }\n-        // rescale if necessary\n-        for (int j = 0; j < nC; ++j) {\n-            diag[j] = FastMath.max(diag[j], jacNorm[j]);\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n         }\n-        // Inner loop.\n-        for (double ratio = 0; ratio < 1.0e-4; ) {\n-            // save the state\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                oldX[pj] = currentPoint[pj];\n-            }\n-            final double previousCost = currentCost;\n-            double[] tmpVec = weightedResidual;\n-            weightedResidual = oldRes;\n-            oldRes = tmpVec;\n-            tmpVec = currentObjective;\n-            currentObjective = oldObj;\n-            oldObj = tmpVec;\n-            // determine the Levenberg-Marquardt parameter\n-            determineLMParameter(qtf, delta, diag, work1, work2, work3);\n-            // compute the new point and the norm of the evolution direction\n-            double lmNorm = 0;\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                lmDir[pj] = -lmDir[pj];\n-                currentPoint[pj] = oldX[pj] + lmDir[pj];\n-                double s = diag[pj] * lmDir[pj];\n-                lmNorm += s * s;\n-            }\n-            lmNorm = FastMath.sqrt(lmNorm);\n-            // on the first iteration, adjust the initial step bound.\n-            if (firstIteration) {\n-                delta = FastMath.min(delta, lmNorm);\n-            }\n-            // Evaluate the function at x + p and calculate its norm.\n-            currentObjective = computeObjectiveValue(currentPoint);\n-            currentResiduals = computeResiduals(currentObjective);\n-            current = new PointVectorValuePair(currentPoint, currentObjective);\n-            currentCost = computeCost(currentResiduals);\n-            // compute the scaled actual reduction\n-            double actRed = -1.0;\n-            if (0.1 * currentCost < previousCost) {\n-                double r = currentCost / previousCost;\n-                actRed = 1.0 - r * r;\n-            }\n-            // compute the scaled predicted reduction\n-            // and the scaled directional derivative\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                double dirJ = lmDir[pj];\n-                work1[j] = 0;\n-                for (int i = 0; i <= j; ++i) {\n-                    work1[i] += weightedJacobian[i][pj] * dirJ;\n-                }\n-            }\n-            double coeff1 = 0;\n-            for (int j = 0; j < solvedCols; ++j) {\n-                coeff1 += work1[j] * work1[j];\n-            }\n-            double pc2 = previousCost * previousCost;\n-            coeff1 = coeff1 / pc2;\n-            double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n-            double preRed = coeff1 + 2 * coeff2;\n-            double dirDer = -(coeff1 + coeff2);\n-            // ratio of the actual to the predicted reduction\n-            ratio = (preRed == 0) ? 0 : (actRed / preRed);\n-            // update the step bound\n-            if (ratio <= 0.25) {\n-                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n-                if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {\n-                    tmp = 0.1;\n-                }\n-                delta = tmp * FastMath.min(delta, 10.0 * lmNorm);\n-                lmPar /= tmp;\n-            } else if ((lmPar == 0) || (ratio >= 0.75)) {\n-                delta = 2 * lmNorm;\n-                lmPar *= 0.5;\n-            }\n-            // test for successful iteration.\n-            if (ratio >= 1.0e-4) {\n-                // successful iteration, update the norm\n-                firstIteration = false;\n-                xNorm = 0;\n-                for (int k = 0; k < nC; ++k) {\n-                    double xK = diag[k] * currentPoint[k];\n-                    xNorm += xK * xK;\n-                }\n-                xNorm = FastMath.sqrt(xNorm);\n-                // tests for convergence.\n-                if (checker != null) {\n-                    // we use the vectorial convergence checker\n-                    if (checker.converged(iter, previous, current)) {\n-                        setCost(currentCost);\n-                        return current;\n-                    }\n-                }\n-            } else {\n-                // failed iteration, reset the previous values\n-                currentCost = previousCost;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    currentPoint[pj] = oldX[pj];\n-                }\n-                tmpVec = weightedResidual;\n-                weightedResidual = oldRes;\n-                oldRes = tmpVec;\n-                tmpVec = currentObjective;\n-                currentObjective = oldObj;\n-                oldObj = tmpVec;\n-                // Reset \"current\" to previous values.\n-                current = new PointVectorValuePair(currentPoint, currentObjective);\n-            }\n-            // Default convergence criteria.\n-            if ((FastMath.abs(actRed) <= costRelativeTolerance && preRed <= costRelativeTolerance && ratio <= 2.0) || delta <= parRelativeTolerance * xNorm) {\n-                setCost(currentCost);\n-                return current;\n-            }\n-            // tests for termination and stringent tolerances\n-            // (2.2204e-16 is the machine epsilon for IEEE754)\n-            if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n-                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);\n-            } else if (delta <= 2.2204e-16 * xNorm) {\n-                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);\n-            } else if (maxCosine <= 2.2204e-16) {\n-                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n     }\n", "finish_reason": "stop", "valid": false, "num": 1}, {"output": "The specific bug in the provided code is not clearly mentioned. However, here is a fixed version of the function with some modifications:\n\n@Override\nprotected PointValuePair doOptimize() {\n    checkParameters();\n    final GoalType goal = getGoalType();\n    final double[] guess = getStartPoint();\n    final int n = guess.length;\n    final double[][] direc = new double[n][n];\n    for (int i = 0; i < n; i++) {\n        direc[i][i] = 1;\n    }\n    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n    double[] x = guess;\n    double fVal = computeObjectiveValue(x);\n    double[] x1 = x.clone();\n    int iter = 0;\n    int maxIter = getMaxIterations(); //added this line to get the maximum number of iterations\n    while (true) {\n        ++iter;\n        if(iter > maxIter){ //added this if block to break the loop if the maximum number of iterations is reached\n            break;\n        }\n        double fX = fVal;\n        double fX2 = 0;\n        double delta = 0;\n        int bigInd = 0;\n        double alphaMin = 0;\n        for (int i = 0; i < n; i++) {\n            final double[] d = MathArrays.copyOf(direc[i]);\n            fX2 = fVal;\n            final UnivariatePointValuePair optimum = line.search(x, d);\n            fVal = optimum.getValue();\n            alphaMin = optimum.getPoint();\n            final double[][] result = newPointAndDirection(x, d, alphaMin);\n            x = result[0];\n            if ((fX2 - fVal) > delta) {\n                delta = fX2 - fVal;\n                bigInd = i;\n            }\n        }\n        // Default convergence check.\n        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n        final PointValuePair previous = new PointValuePair(x1, fX);\n        final PointValuePair current = new PointValuePair(x, fVal);\n        if (!stop) {\n            // User-defined stopping criteria.\n            if (checker != null) {\n                stop = checker.converged(iter, previous, current);\n            }\n        }\n        if (stop) {\n            if (goal == GoalType.MINIMIZE) {\n                return (fVal < fX) ? current : previous;\n            } else {\n                return (fVal > fX) ? current : previous;\n            }\n        }\n        final double[] d = new double[n];\n        final double[] x2 = new double[n];\n        for (int i = 0; i < n; i++) {\n            d[i] = x[i] - x1[i];\n            x2[i] = 2 * x[i] - x1[i];\n        }\n        x1 = x.clone();\n        fX2 = computeObjectiveValue(x2);\n        if (fX > fX2) {\n            double t = 2 * (fX + fX2 - 2 * fVal);\n            double temp = fX - fVal - delta;\n            t *= temp * temp;\n            temp = fX - fX2;\n            t -= delta * temp * temp;\n            if (t < 0.0) {\n                final UnivariatePointValuePair optimum = line.search(x, d);\n                fVal = optimum.getValue();\n                alphaMin = optimum.getPoint();\n                final double[][] result = newPointAndDirection(x, d, alphaMin);\n                x = result[0];\n                final int lastInd = n - 1;\n                direc[bigInd] = direc[lastInd];\n                direc[lastInd] = result[1];\n            }\n        }\n    }\n    return new PointValuePair(x, fVal); //added this line\n} \n\nThe changes made to the function are:\n\n1. Added a line to get the maximum number of iterations allowed from the input.\n2. Added an if block to break the loop if the maximum number of iterations is reached.\n3. Added a return statement outside the while loop to ensure that the function always returns a result.", "diff": "--- org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizer.java@doOptimize\n@@ -1,88 +1,84 @@\n @Override\n protected PointValuePair doOptimize() {\n+    checkParameters();\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n     final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n-    final double[] point = getStartPoint();\n-    final GoalType goal = getGoalType();\n-    final int n = point.length;\n-    double[] r = computeObjectiveGradient(point);\n-    if (goal == GoalType.MINIMIZE) {\n-        for (int i = 0; i < n; i++) {\n-            r[i] = -r[i];\n-        }\n-    }\n-    // Initial search direction.\n-    double[] steepestDescent = preconditioner.precondition(point, r);\n-    double[] searchDirection = steepestDescent.clone();\n-    double delta = 0;\n-    for (int i = 0; i < n; ++i) {\n-        delta += r[i] * searchDirection[i];\n-    }\n-    PointValuePair current = null;\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n     int iter = 0;\n-    int maxEval = getMaxEvaluations();\n+    int maxIter = getMaxIterations(); //added this line to get the maximum number of iterations\n     while (true) {\n         ++iter;\n-        final double objective = computeObjectiveValue(point);\n-        PointValuePair previous = current;\n-        current = new PointValuePair(point, objective);\n-        if (previous != null) {\n-            if (checker.converged(iter, previous, current)) {\n-                // We have found an optimum.\n-                return current;\n+        if(iter > maxIter){ //added this if block to break the loop if the maximum number of iterations is reached\n+            break;\n+        }\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = line.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        // Find the optimal step in the search direction.\n-        final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);\n-        final double uB = findUpperBound(lsf, 0, initialStep);\n-        // XXX Last parameters is set to a value close to zero in order to\n-        // work around the divergence problem in the \"testCircleFitting\"\n-        // unit test (see MATH-439).\n-        final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);\n-        // Subtract used up evaluations.\n-        maxEval -= solver.getEvaluations();\n-        // Validate new point.\n-        for (int i = 0; i < point.length; ++i) {\n-            point[i] += step * searchDirection[i];\n-        }\n-        r = computeObjectiveGradient(point);\n-        if (goal == GoalType.MINIMIZE) {\n-            for (int i = 0; i < n; ++i) {\n-                r[i] = -r[i];\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n             }\n         }\n-        // Compute beta.\n-        final double deltaOld = delta;\n-        final double[] newSteepestDescent = preconditioner.precondition(point, r);\n-        delta = 0;\n-        for (int i = 0; i < n; ++i) {\n-            delta += r[i] * newSteepestDescent[i];\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n         }\n-        final double beta;\n-        switch(updateFormula) {\n-            case FLETCHER_REEVES:\n-                beta = delta / deltaOld;\n-                break;\n-            case POLAK_RIBIERE:\n-                double deltaMid = 0;\n-                for (int i = 0; i < r.length; ++i) {\n-                    deltaMid += r[i] * steepestDescent[i];\n-                }\n-                beta = (delta - deltaMid) / deltaOld;\n-                break;\n-            default:\n-                // Should never happen.\n-                throw new MathInternalError();\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n         }\n-        steepestDescent = newSteepestDescent;\n-        // Compute conjugate search direction.\n-        if (iter % n == 0 || beta < 0) {\n-            // Break conjugation: reset search direction.\n-            searchDirection = steepestDescent.clone();\n-        } else {\n-            // Compute new conjugate search direction.\n-            for (int i = 0; i < n; ++i) {\n-                searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = line.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n     }\n+    return new PointValuePair(x, fVal); //added this line\n }\n--- org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizer.java@doOptimize\n@@ -1,135 +1,84 @@\n @Override\n protected PointValuePair doOptimize() {\n-    // -------------------- Initialization --------------------------------\n-    isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n-    final FitnessFunction fitfun = new FitnessFunction();\n+    checkParameters();\n+    final GoalType goal = getGoalType();\n     final double[] guess = getStartPoint();\n-    // number of objective variables/problem dimension\n-    dimension = guess.length;\n-    initializeCMA(guess);\n-    iterations = 0;\n-    double bestValue = fitfun.value(guess);\n-    push(fitnessHistory, bestValue);\n-    PointValuePair optimum = new PointValuePair(getStartPoint(), isMinimize ? bestValue : -bestValue);\n-    PointValuePair lastResult = null;\n-    // -------------------- Generation Loop --------------------------------\n-    generationLoop: for (iterations = 1; iterations <= maxIterations; iterations++) {\n-        // Generate and evaluate lambda offspring\n-        final RealMatrix arz = randn1(dimension, lambda);\n-        final RealMatrix arx = zeros(dimension, lambda);\n-        final double[] fitness = new double[lambda];\n-        // generate random offspring\n-        for (int k = 0; k < lambda; k++) {\n-            RealMatrix arxk = null;\n-            for (int i = 0; i < checkFeasableCount + 1; i++) {\n-                if (diagonalOnly <= 0) {\n-                    arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k)).scalarMultiply(// m + sig * Normal(0,C)\n-                    sigma));\n-                } else {\n-                    arxk = xmean.add(times(diagD, arz.getColumnMatrix(k)).scalarMultiply(sigma));\n-                }\n-                if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {\n-                    break;\n-                }\n-                // regenerate random arguments for row\n-                arz.setColumn(k, randn(dimension));\n-            }\n-            copyColumn(arxk, 0, arx, k);\n-            try {\n-                // compute fitness\n-                fitness[k] = fitfun.value(arx.getColumn(k));\n-            } catch (TooManyEvaluationsException e) {\n-                break generationLoop;\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n+    int iter = 0;\n+    int maxIter = getMaxIterations(); //added this line to get the maximum number of iterations\n+    while (true) {\n+        ++iter;\n+        if(iter > maxIter){ //added this if block to break the loop if the maximum number of iterations is reached\n+            break;\n+        }\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = line.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        // Sort by fitness and compute weighted mean into xmean\n-        final int[] arindex = sortedIndices(fitness);\n-        // Calculate new xmean, this is selection and recombination\n-        // for speed up of Eq. (2) and (3)\n-        final RealMatrix xold = xmean;\n-        final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n-        xmean = bestArx.multiply(weights);\n-        final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n-        final RealMatrix zmean = bestArz.multiply(weights);\n-        final boolean hsig = updateEvolutionPaths(zmean, xold);\n-        if (diagonalOnly <= 0) {\n-            updateCovariance(hsig, bestArx, arz, arindex, xold);\n-        } else {\n-            updateCovarianceDiagonalOnly(hsig, bestArz);\n-        }\n-        // Adapt step size sigma - Eq. (5)\n-        sigma *= Math.exp(Math.min(1, (normps / chiN - 1) * cs / damps));\n-        final double bestFitness = fitness[arindex[0]];\n-        final double worstFitness = fitness[arindex[arindex.length - 1]];\n-        if (bestValue > bestFitness) {\n-            bestValue = bestFitness;\n-            lastResult = optimum;\n-            optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)), isMinimize ? bestFitness : -bestFitness);\n-            if (getConvergenceChecker() != null && lastResult != null) {\n-                if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n-                    break generationLoop;\n-                }\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n             }\n         }\n-        // handle termination criteria\n-        // Break, if fitness is good enough\n-        if (stopFitness != 0) {\n-            // only if stopFitness is defined\n-            if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n-                break generationLoop;\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n             }\n         }\n-        final double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n-        final double[] pcCol = pc.getColumn(0);\n-        for (int i = 0; i < dimension; i++) {\n-            if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) {\n-                break;\n-            }\n-            if (i >= dimension - 1) {\n-                break generationLoop;\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = line.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n-        for (int i = 0; i < dimension; i++) {\n-            if (sigma * sqrtDiagC[i] > stopTolUpX) {\n-                break generationLoop;\n-            }\n-        }\n-        final double historyBest = min(fitnessHistory);\n-        final double historyWorst = max(fitnessHistory);\n-        if (iterations > 2 && Math.max(historyWorst, worstFitness) - Math.min(historyBest, bestFitness) < stopTolFun) {\n-            break generationLoop;\n-        }\n-        if (iterations > fitnessHistory.length && historyWorst - historyBest < stopTolHistFun) {\n-            break generationLoop;\n-        }\n-        // condition number of the covariance matrix exceeds 1e14\n-        if (max(diagD) / min(diagD) > 1e7) {\n-            break generationLoop;\n-        }\n-        // user defined termination\n-        if (getConvergenceChecker() != null) {\n-            final PointValuePair current = new PointValuePair(bestArx.getColumn(0), isMinimize ? bestFitness : -bestFitness);\n-            if (lastResult != null && getConvergenceChecker().converged(iterations, current, lastResult)) {\n-                break generationLoop;\n-            }\n-            lastResult = current;\n-        }\n-        // Adjust step size in case of equal function values (flat fitness)\n-        if (bestValue == fitness[arindex[(int) (0.1 + lambda / 4.)]]) {\n-            sigma = sigma * Math.exp(0.2 + cs / damps);\n-        }\n-        if (iterations > 2 && Math.max(historyWorst, bestFitness) - Math.min(historyBest, bestFitness) == 0) {\n-            sigma = sigma * Math.exp(0.2 + cs / damps);\n-        }\n-        // store best in history\n-        push(fitnessHistory, bestFitness);\n-        fitfun.setValueRange(worstFitness - bestFitness);\n-        if (generateStatistics) {\n-            statisticsSigmaHistory.add(sigma);\n-            statisticsFitnessHistory.add(bestFitness);\n-            statisticsMeanHistory.add(xmean.transpose());\n-            statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n-        }\n     }\n-    return optimum;\n+    return new PointValuePair(x, fVal); //added this line\n }\n--- org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizer.java@doOptimize\n@@ -13,8 +13,12 @@\n     double fVal = computeObjectiveValue(x);\n     double[] x1 = x.clone();\n     int iter = 0;\n+    int maxIter = getMaxIterations(); //added this line to get the maximum number of iterations\n     while (true) {\n         ++iter;\n+        if(iter > maxIter){ //added this if block to break the loop if the maximum number of iterations is reached\n+            break;\n+        }\n         double fX = fVal;\n         double fX2 = 0;\n         double delta = 0;\n@@ -76,4 +80,5 @@\n             }\n         }\n     }\n+    return new PointValuePair(x, fVal); //added this line\n }\n--- org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizer.java@doOptimize\n@@ -1,44 +1,84 @@\n @Override\n protected PointValuePair doOptimize() {\n     checkParameters();\n-    // Indirect call to \"computeObjectiveValue\" in order to update the\n-    // evaluations counter.\n-    final MultivariateFunction evalFunc = new MultivariateFunction() {\n-\n-        public double value(double[] point) {\n-            return computeObjectiveValue(point);\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n+    int iter = 0;\n+    int maxIter = getMaxIterations(); //added this line to get the maximum number of iterations\n+    while (true) {\n+        ++iter;\n+        if(iter > maxIter){ //added this if block to break the loop if the maximum number of iterations is reached\n+            break;\n         }\n-    };\n-    final boolean isMinim = getGoalType() == GoalType.MINIMIZE;\n-    final Comparator<PointValuePair> comparator = new Comparator<PointValuePair>() {\n-\n-        public int compare(final PointValuePair o1, final PointValuePair o2) {\n-            final double v1 = o1.getValue();\n-            final double v2 = o2.getValue();\n-            return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1);\n-        }\n-    };\n-    // Initialize search.\n-    simplex.build(getStartPoint());\n-    simplex.evaluate(evalFunc, comparator);\n-    PointValuePair[] previous = null;\n-    int iteration = 0;\n-    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n-    while (true) {\n-        if (iteration > 0) {\n-            boolean converged = true;\n-            for (int i = 0; i < simplex.getSize(); i++) {\n-                PointValuePair prev = previous[i];\n-                converged = converged && checker.converged(iteration, prev, simplex.getPoint(i));\n-            }\n-            if (converged) {\n-                // We have found an optimum.\n-                return simplex.getPoint(0);\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = line.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        // We still need to search.\n-        previous = simplex.getPoints();\n-        simplex.iterate(evalFunc, comparator);\n-        ++iteration;\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n+            }\n+        }\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n+        }\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = line.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n+            }\n+        }\n     }\n+    return new PointValuePair(x, fVal); //added this line\n }\n--- org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizer.java@doOptimize\n@@ -1,76 +1,84 @@\n @Override\n-public PointVectorValuePair doOptimize() {\n+protected PointValuePair doOptimize() {\n     checkParameters();\n-    final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n-    // Computation will be useless without a checker (see \"for-loop\").\n-    if (checker == null) {\n-        throw new NullArgumentException();\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n     }\n-    final double[] targetValues = getTarget();\n-    // Number of observed data.\n-    final int nR = targetValues.length;\n-    final RealMatrix weightMatrix = getWeight();\n-    // Diagonal of the weight matrix.\n-    final double[] residualsWeights = new double[nR];\n-    for (int i = 0; i < nR; i++) {\n-        residualsWeights[i] = weightMatrix.getEntry(i, i);\n-    }\n-    final double[] currentPoint = getStartPoint();\n-    final int nC = currentPoint.length;\n-    // iterate until convergence is reached\n-    PointVectorValuePair current = null;\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n     int iter = 0;\n-    for (boolean converged = false; !converged; ) {\n+    int maxIter = getMaxIterations(); //added this line to get the maximum number of iterations\n+    while (true) {\n         ++iter;\n-        // evaluate the objective function and its jacobian\n-        PointVectorValuePair previous = current;\n-        // Value of the objective function at \"currentPoint\".\n-        final double[] currentObjective = computeObjectiveValue(currentPoint);\n-        final double[] currentResiduals = computeResiduals(currentObjective);\n-        final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint);\n-        current = new PointVectorValuePair(currentPoint, currentObjective);\n-        // build the linear problem\n-        final double[] b = new double[nC];\n-        final double[][] a = new double[nC][nC];\n-        for (int i = 0; i < nR; ++i) {\n-            final double[] grad = weightedJacobian.getRow(i);\n-            final double weight = residualsWeights[i];\n-            final double residual = currentResiduals[i];\n-            // compute the normal equation\n-            final double wr = weight * residual;\n-            for (int j = 0; j < nC; ++j) {\n-                b[j] += wr * grad[j];\n-            }\n-            // build the contribution matrix for measurement i\n-            for (int k = 0; k < nC; ++k) {\n-                double[] ak = a[k];\n-                double wgk = weight * grad[k];\n-                for (int l = 0; l < nC; ++l) {\n-                    ak[l] += wgk * grad[l];\n-                }\n+        if(iter > maxIter){ //added this if block to break the loop if the maximum number of iterations is reached\n+            break;\n+        }\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = line.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        try {\n-            // solve the linearized least squares problem\n-            RealMatrix mA = new BlockRealMatrix(a);\n-            DecompositionSolver solver = useLU ? new LUDecomposition(mA).getSolver() : new QRDecomposition(mA).getSolver();\n-            final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray();\n-            // update the estimated parameters\n-            for (int i = 0; i < nC; ++i) {\n-                currentPoint[i] += dX[i];\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n             }\n-        } catch (SingularMatrixException e) {\n-            throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM);\n         }\n-        // Check convergence.\n-        if (previous != null) {\n-            converged = checker.converged(iter, previous, current);\n-            if (converged) {\n-                setCost(computeCost(currentResiduals));\n-                return current;\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n+        }\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = line.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n     }\n-    // Must never happen.\n-    throw new MathInternalError();\n+    return new PointValuePair(x, fVal); //added this line\n }\n--- org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizer.java@doOptimize\n@@ -1,220 +1,84 @@\n @Override\n-protected PointVectorValuePair doOptimize() {\n+protected PointValuePair doOptimize() {\n     checkParameters();\n-    // Number of observed data.\n-    final int nR = getTarget().length;\n-    final double[] currentPoint = getStartPoint();\n-    // Number of parameters.\n-    final int nC = currentPoint.length;\n-    // arrays shared with the other private methods\n-    solvedCols = FastMath.min(nR, nC);\n-    diagR = new double[nC];\n-    jacNorm = new double[nC];\n-    beta = new double[nC];\n-    permutation = new int[nC];\n-    lmDir = new double[nC];\n-    // local point\n-    double delta = 0;\n-    double xNorm = 0;\n-    double[] diag = new double[nC];\n-    double[] oldX = new double[nC];\n-    double[] oldRes = new double[nR];\n-    double[] oldObj = new double[nR];\n-    double[] qtf = new double[nR];\n-    double[] work1 = new double[nC];\n-    double[] work2 = new double[nC];\n-    double[] work3 = new double[nC];\n-    final RealMatrix weightMatrixSqrt = getWeightSquareRoot();\n-    // Evaluate the function at the starting point and calculate its norm.\n-    double[] currentObjective = computeObjectiveValue(currentPoint);\n-    double[] currentResiduals = computeResiduals(currentObjective);\n-    PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);\n-    double currentCost = computeCost(currentResiduals);\n-    // Outer loop.\n-    lmPar = 0;\n-    boolean firstIteration = true;\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n     int iter = 0;\n-    final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n+    int maxIter = getMaxIterations(); //added this line to get the maximum number of iterations\n     while (true) {\n         ++iter;\n-        final PointVectorValuePair previous = current;\n-        // QR decomposition of the jacobian matrix\n-        qrDecomposition(computeWeightedJacobian(currentPoint));\n-        weightedResidual = weightMatrixSqrt.operate(currentResiduals);\n-        for (int i = 0; i < nR; i++) {\n-            qtf[i] = weightedResidual[i];\n+        if(iter > maxIter){ //added this if block to break the loop if the maximum number of iterations is reached\n+            break;\n         }\n-        // compute Qt.res\n-        qTy(qtf);\n-        // now we don't need Q anymore,\n-        // so let jacobian contain the R matrix with its diagonal elements\n-        for (int k = 0; k < solvedCols; ++k) {\n-            int pk = permutation[k];\n-            weightedJacobian[k][pk] = diagR[pk];\n-        }\n-        if (firstIteration) {\n-            // scale the point according to the norms of the columns\n-            // of the initial jacobian\n-            xNorm = 0;\n-            for (int k = 0; k < nC; ++k) {\n-                double dk = jacNorm[k];\n-                if (dk == 0) {\n-                    dk = 1.0;\n-                }\n-                double xk = dk * currentPoint[k];\n-                xNorm += xk * xk;\n-                diag[k] = dk;\n-            }\n-            xNorm = FastMath.sqrt(xNorm);\n-            // initialize the step bound delta\n-            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n-        }\n-        // check orthogonality between function vector and jacobian columns\n-        double maxCosine = 0;\n-        if (currentCost != 0) {\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                double s = jacNorm[pj];\n-                if (s != 0) {\n-                    double sum = 0;\n-                    for (int i = 0; i <= j; ++i) {\n-                        sum += weightedJacobian[i][pj] * qtf[i];\n-                    }\n-                    maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));\n-                }\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = line.search(x, d);\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        if (maxCosine <= orthoTolerance) {\n-            // Convergence has been reached.\n-            setCost(currentCost);\n-            return current;\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n+            }\n         }\n-        // rescale if necessary\n-        for (int j = 0; j < nC; ++j) {\n-            diag[j] = FastMath.max(diag[j], jacNorm[j]);\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n         }\n-        // Inner loop.\n-        for (double ratio = 0; ratio < 1.0e-4; ) {\n-            // save the state\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                oldX[pj] = currentPoint[pj];\n-            }\n-            final double previousCost = currentCost;\n-            double[] tmpVec = weightedResidual;\n-            weightedResidual = oldRes;\n-            oldRes = tmpVec;\n-            tmpVec = currentObjective;\n-            currentObjective = oldObj;\n-            oldObj = tmpVec;\n-            // determine the Levenberg-Marquardt parameter\n-            determineLMParameter(qtf, delta, diag, work1, work2, work3);\n-            // compute the new point and the norm of the evolution direction\n-            double lmNorm = 0;\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                lmDir[pj] = -lmDir[pj];\n-                currentPoint[pj] = oldX[pj] + lmDir[pj];\n-                double s = diag[pj] * lmDir[pj];\n-                lmNorm += s * s;\n-            }\n-            lmNorm = FastMath.sqrt(lmNorm);\n-            // on the first iteration, adjust the initial step bound.\n-            if (firstIteration) {\n-                delta = FastMath.min(delta, lmNorm);\n-            }\n-            // Evaluate the function at x + p and calculate its norm.\n-            currentObjective = computeObjectiveValue(currentPoint);\n-            currentResiduals = computeResiduals(currentObjective);\n-            current = new PointVectorValuePair(currentPoint, currentObjective);\n-            currentCost = computeCost(currentResiduals);\n-            // compute the scaled actual reduction\n-            double actRed = -1.0;\n-            if (0.1 * currentCost < previousCost) {\n-                double r = currentCost / previousCost;\n-                actRed = 1.0 - r * r;\n-            }\n-            // compute the scaled predicted reduction\n-            // and the scaled directional derivative\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                double dirJ = lmDir[pj];\n-                work1[j] = 0;\n-                for (int i = 0; i <= j; ++i) {\n-                    work1[i] += weightedJacobian[i][pj] * dirJ;\n-                }\n-            }\n-            double coeff1 = 0;\n-            for (int j = 0; j < solvedCols; ++j) {\n-                coeff1 += work1[j] * work1[j];\n-            }\n-            double pc2 = previousCost * previousCost;\n-            coeff1 = coeff1 / pc2;\n-            double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n-            double preRed = coeff1 + 2 * coeff2;\n-            double dirDer = -(coeff1 + coeff2);\n-            // ratio of the actual to the predicted reduction\n-            ratio = (preRed == 0) ? 0 : (actRed / preRed);\n-            // update the step bound\n-            if (ratio <= 0.25) {\n-                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n-                if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {\n-                    tmp = 0.1;\n-                }\n-                delta = tmp * FastMath.min(delta, 10.0 * lmNorm);\n-                lmPar /= tmp;\n-            } else if ((lmPar == 0) || (ratio >= 0.75)) {\n-                delta = 2 * lmNorm;\n-                lmPar *= 0.5;\n-            }\n-            // test for successful iteration.\n-            if (ratio >= 1.0e-4) {\n-                // successful iteration, update the norm\n-                firstIteration = false;\n-                xNorm = 0;\n-                for (int k = 0; k < nC; ++k) {\n-                    double xK = diag[k] * currentPoint[k];\n-                    xNorm += xK * xK;\n-                }\n-                xNorm = FastMath.sqrt(xNorm);\n-                // tests for convergence.\n-                if (checker != null) {\n-                    // we use the vectorial convergence checker\n-                    if (checker.converged(iter, previous, current)) {\n-                        setCost(currentCost);\n-                        return current;\n-                    }\n-                }\n-            } else {\n-                // failed iteration, reset the previous values\n-                currentCost = previousCost;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    currentPoint[pj] = oldX[pj];\n-                }\n-                tmpVec = weightedResidual;\n-                weightedResidual = oldRes;\n-                oldRes = tmpVec;\n-                tmpVec = currentObjective;\n-                currentObjective = oldObj;\n-                oldObj = tmpVec;\n-                // Reset \"current\" to previous values.\n-                current = new PointVectorValuePair(currentPoint, currentObjective);\n-            }\n-            // Default convergence criteria.\n-            if ((FastMath.abs(actRed) <= costRelativeTolerance && preRed <= costRelativeTolerance && ratio <= 2.0) || delta <= parRelativeTolerance * xNorm) {\n-                setCost(currentCost);\n-                return current;\n-            }\n-            // tests for termination and stringent tolerances\n-            // (2.2204e-16 is the machine epsilon for IEEE754)\n-            if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n-                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);\n-            } else if (delta <= 2.2204e-16 * xNorm) {\n-                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);\n-            } else if (maxCosine <= 2.2204e-16) {\n-                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = line.search(x, d);\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n     }\n+    return new PointValuePair(x, fVal); //added this line\n }\n", "finish_reason": "stop", "valid": false, "num": 1}, {"output": "@Override\nprotected PointValuePair doOptimize() {\n    checkParameters();\n    final GoalType goal = getGoalType();\n    final double[] guess = getStartPoint();\n    final int n = guess.length;\n    final double[][] direc = new double[n][n];\n    for (int i = 0; i < n; i++) {\n        direc[i][i] = 1;\n    }\n    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n    double[] x = guess;\n    double fVal = computeObjectiveValue(x);\n    double[] x1 = x.clone();\n    int iter = 0;\n    while (true) {\n        ++iter;\n        double fX = fVal;\n        double fX2 = 0;\n        double delta = 0;\n        int bigInd = 0;\n        double alphaMin = 0;\n        for (int i = 0; i < n; i++) {\n            final double[] d = MathArrays.copyOf(direc[i]);\n            fX2 = fVal;\n            final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n            fVal = optimum.getValue();\n            alphaMin = optimum.getPoint();\n            final double[][] result = newPointAndDirection(x, d, alphaMin);\n            x = result[0];\n            if ((fX2 - fVal) > delta) {\n                delta = fX2 - fVal;\n                bigInd = i;\n            }\n        }\n        // Default convergence check.\n        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n        final PointValuePair previous = new PointValuePair(x1, fX);\n        final PointValuePair current = new PointValuePair(x, fVal);\n        if (!stop) {\n            // User-defined stopping criteria.\n            if (checker != null) {\n                stop = checker.converged(iter, previous, current);\n            }\n        }\n        if (stop) {\n            if (goal == GoalType.MINIMIZE) {\n                return (fVal < fX) ? current : previous;\n            } else {\n                return (fVal > fX) ? current : previous;\n            }\n        }\n        final double[] d = new double[n];\n        final double[] x2 = new double[n];\n        for (int i = 0; i < n; i++) {\n            d[i] = x[i] - x1[i];\n            x2[i] = 2 * x[i] - x1[i];\n        }\n        x1 = x.clone();\n        fX2 = computeObjectiveValue(x2);\n        if (fX > fX2) {\n            double t = 2 * (fX + fX2 - 2 * fVal);\n            double temp = fX - fVal - delta;\n            t *= temp * temp;\n            temp = fX - fX2;\n            t -= delta * temp * temp;\n            if (t < 0.0) {\n                final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n                fVal = optimum.getValue();\n                alphaMin = optimum.getPoint();\n                final double[][] result = newPointAndDirection(x, d, alphaMin);\n                x = result[0];\n                final int lastInd = n - 1;\n                direc[bigInd] = direc[lastInd];\n                direc[lastInd] = result[1];\n            }\n        }\n    }\n}", "diff": "--- org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizer.java@doOptimize\n@@ -1,87 +1,78 @@\n @Override\n protected PointValuePair doOptimize() {\n+    checkParameters();\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n     final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n-    final double[] point = getStartPoint();\n-    final GoalType goal = getGoalType();\n-    final int n = point.length;\n-    double[] r = computeObjectiveGradient(point);\n-    if (goal == GoalType.MINIMIZE) {\n-        for (int i = 0; i < n; i++) {\n-            r[i] = -r[i];\n-        }\n-    }\n-    // Initial search direction.\n-    double[] steepestDescent = preconditioner.precondition(point, r);\n-    double[] searchDirection = steepestDescent.clone();\n-    double delta = 0;\n-    for (int i = 0; i < n; ++i) {\n-        delta += r[i] * searchDirection[i];\n-    }\n-    PointValuePair current = null;\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n     int iter = 0;\n-    int maxEval = getMaxEvaluations();\n     while (true) {\n         ++iter;\n-        final double objective = computeObjectiveValue(point);\n-        PointValuePair previous = current;\n-        current = new PointValuePair(point, objective);\n-        if (previous != null) {\n-            if (checker.converged(iter, previous, current)) {\n-                // We have found an optimum.\n-                return current;\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        // Find the optimal step in the search direction.\n-        final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);\n-        final double uB = findUpperBound(lsf, 0, initialStep);\n-        // XXX Last parameters is set to a value close to zero in order to\n-        // work around the divergence problem in the \"testCircleFitting\"\n-        // unit test (see MATH-439).\n-        final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);\n-        // Subtract used up evaluations.\n-        maxEval -= solver.getEvaluations();\n-        // Validate new point.\n-        for (int i = 0; i < point.length; ++i) {\n-            point[i] += step * searchDirection[i];\n-        }\n-        r = computeObjectiveGradient(point);\n-        if (goal == GoalType.MINIMIZE) {\n-            for (int i = 0; i < n; ++i) {\n-                r[i] = -r[i];\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n             }\n         }\n-        // Compute beta.\n-        final double deltaOld = delta;\n-        final double[] newSteepestDescent = preconditioner.precondition(point, r);\n-        delta = 0;\n-        for (int i = 0; i < n; ++i) {\n-            delta += r[i] * newSteepestDescent[i];\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n         }\n-        final double beta;\n-        switch(updateFormula) {\n-            case FLETCHER_REEVES:\n-                beta = delta / deltaOld;\n-                break;\n-            case POLAK_RIBIERE:\n-                double deltaMid = 0;\n-                for (int i = 0; i < r.length; ++i) {\n-                    deltaMid += r[i] * steepestDescent[i];\n-                }\n-                beta = (delta - deltaMid) / deltaOld;\n-                break;\n-            default:\n-                // Should never happen.\n-                throw new MathInternalError();\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n         }\n-        steepestDescent = newSteepestDescent;\n-        // Compute conjugate search direction.\n-        if (iter % n == 0 || beta < 0) {\n-            // Break conjugation: reset search direction.\n-            searchDirection = steepestDescent.clone();\n-        } else {\n-            // Compute new conjugate search direction.\n-            for (int i = 0; i < n; ++i) {\n-                searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n     }\n--- org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizer.java@doOptimize\n@@ -1,135 +1,79 @@\n @Override\n protected PointValuePair doOptimize() {\n-    // -------------------- Initialization --------------------------------\n-    isMinimize = getGoalType().equals(GoalType.MINIMIZE);\n-    final FitnessFunction fitfun = new FitnessFunction();\n+    checkParameters();\n+    final GoalType goal = getGoalType();\n     final double[] guess = getStartPoint();\n-    // number of objective variables/problem dimension\n-    dimension = guess.length;\n-    initializeCMA(guess);\n-    iterations = 0;\n-    double bestValue = fitfun.value(guess);\n-    push(fitnessHistory, bestValue);\n-    PointValuePair optimum = new PointValuePair(getStartPoint(), isMinimize ? bestValue : -bestValue);\n-    PointValuePair lastResult = null;\n-    // -------------------- Generation Loop --------------------------------\n-    generationLoop: for (iterations = 1; iterations <= maxIterations; iterations++) {\n-        // Generate and evaluate lambda offspring\n-        final RealMatrix arz = randn1(dimension, lambda);\n-        final RealMatrix arx = zeros(dimension, lambda);\n-        final double[] fitness = new double[lambda];\n-        // generate random offspring\n-        for (int k = 0; k < lambda; k++) {\n-            RealMatrix arxk = null;\n-            for (int i = 0; i < checkFeasableCount + 1; i++) {\n-                if (diagonalOnly <= 0) {\n-                    arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k)).scalarMultiply(// m + sig * Normal(0,C)\n-                    sigma));\n-                } else {\n-                    arxk = xmean.add(times(diagD, arz.getColumnMatrix(k)).scalarMultiply(sigma));\n-                }\n-                if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {\n-                    break;\n-                }\n-                // regenerate random arguments for row\n-                arz.setColumn(k, randn(dimension));\n-            }\n-            copyColumn(arxk, 0, arx, k);\n-            try {\n-                // compute fitness\n-                fitness[k] = fitfun.value(arx.getColumn(k));\n-            } catch (TooManyEvaluationsException e) {\n-                break generationLoop;\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n+    int iter = 0;\n+    while (true) {\n+        ++iter;\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        // Sort by fitness and compute weighted mean into xmean\n-        final int[] arindex = sortedIndices(fitness);\n-        // Calculate new xmean, this is selection and recombination\n-        // for speed up of Eq. (2) and (3)\n-        final RealMatrix xold = xmean;\n-        final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\n-        xmean = bestArx.multiply(weights);\n-        final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\n-        final RealMatrix zmean = bestArz.multiply(weights);\n-        final boolean hsig = updateEvolutionPaths(zmean, xold);\n-        if (diagonalOnly <= 0) {\n-            updateCovariance(hsig, bestArx, arz, arindex, xold);\n-        } else {\n-            updateCovarianceDiagonalOnly(hsig, bestArz);\n-        }\n-        // Adapt step size sigma - Eq. (5)\n-        sigma *= Math.exp(Math.min(1, (normps / chiN - 1) * cs / damps));\n-        final double bestFitness = fitness[arindex[0]];\n-        final double worstFitness = fitness[arindex[arindex.length - 1]];\n-        if (bestValue > bestFitness) {\n-            bestValue = bestFitness;\n-            lastResult = optimum;\n-            optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)), isMinimize ? bestFitness : -bestFitness);\n-            if (getConvergenceChecker() != null && lastResult != null) {\n-                if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\n-                    break generationLoop;\n-                }\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n             }\n         }\n-        // handle termination criteria\n-        // Break, if fitness is good enough\n-        if (stopFitness != 0) {\n-            // only if stopFitness is defined\n-            if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {\n-                break generationLoop;\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n             }\n         }\n-        final double[] sqrtDiagC = sqrt(diagC).getColumn(0);\n-        final double[] pcCol = pc.getColumn(0);\n-        for (int i = 0; i < dimension; i++) {\n-            if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) {\n-                break;\n-            }\n-            if (i >= dimension - 1) {\n-                break generationLoop;\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n-        for (int i = 0; i < dimension; i++) {\n-            if (sigma * sqrtDiagC[i] > stopTolUpX) {\n-                break generationLoop;\n-            }\n-        }\n-        final double historyBest = min(fitnessHistory);\n-        final double historyWorst = max(fitnessHistory);\n-        if (iterations > 2 && Math.max(historyWorst, worstFitness) - Math.min(historyBest, bestFitness) < stopTolFun) {\n-            break generationLoop;\n-        }\n-        if (iterations > fitnessHistory.length && historyWorst - historyBest < stopTolHistFun) {\n-            break generationLoop;\n-        }\n-        // condition number of the covariance matrix exceeds 1e14\n-        if (max(diagD) / min(diagD) > 1e7) {\n-            break generationLoop;\n-        }\n-        // user defined termination\n-        if (getConvergenceChecker() != null) {\n-            final PointValuePair current = new PointValuePair(bestArx.getColumn(0), isMinimize ? bestFitness : -bestFitness);\n-            if (lastResult != null && getConvergenceChecker().converged(iterations, current, lastResult)) {\n-                break generationLoop;\n-            }\n-            lastResult = current;\n-        }\n-        // Adjust step size in case of equal function values (flat fitness)\n-        if (bestValue == fitness[arindex[(int) (0.1 + lambda / 4.)]]) {\n-            sigma = sigma * Math.exp(0.2 + cs / damps);\n-        }\n-        if (iterations > 2 && Math.max(historyWorst, bestFitness) - Math.min(historyBest, bestFitness) == 0) {\n-            sigma = sigma * Math.exp(0.2 + cs / damps);\n-        }\n-        // store best in history\n-        push(fitnessHistory, bestFitness);\n-        fitfun.setValueRange(worstFitness - bestFitness);\n-        if (generateStatistics) {\n-            statisticsSigmaHistory.add(sigma);\n-            statisticsFitnessHistory.add(bestFitness);\n-            statisticsMeanHistory.add(xmean.transpose());\n-            statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));\n-        }\n     }\n-    return optimum;\n }\n--- org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizer.java@doOptimize\n@@ -23,7 +23,7 @@\n         for (int i = 0; i < n; i++) {\n             final double[] d = MathArrays.copyOf(direc[i]);\n             fX2 = fVal;\n-            final UnivariatePointValuePair optimum = line.search(x, d);\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n             fVal = optimum.getValue();\n             alphaMin = optimum.getPoint();\n             final double[][] result = newPointAndDirection(x, d, alphaMin);\n@@ -65,7 +65,7 @@\n             temp = fX - fX2;\n             t -= delta * temp * temp;\n             if (t < 0.0) {\n-                final UnivariatePointValuePair optimum = line.search(x, d);\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n                 fVal = optimum.getValue();\n                 alphaMin = optimum.getPoint();\n                 final double[][] result = newPointAndDirection(x, d, alphaMin);\n--- org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizer.java@doOptimize\n@@ -1,44 +1,79 @@\n @Override\n protected PointValuePair doOptimize() {\n     checkParameters();\n-    // Indirect call to \"computeObjectiveValue\" in order to update the\n-    // evaluations counter.\n-    final MultivariateFunction evalFunc = new MultivariateFunction() {\n-\n-        public double value(double[] point) {\n-            return computeObjectiveValue(point);\n-        }\n-    };\n-    final boolean isMinim = getGoalType() == GoalType.MINIMIZE;\n-    final Comparator<PointValuePair> comparator = new Comparator<PointValuePair>() {\n-\n-        public int compare(final PointValuePair o1, final PointValuePair o2) {\n-            final double v1 = o1.getValue();\n-            final double v2 = o2.getValue();\n-            return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1);\n-        }\n-    };\n-    // Initialize search.\n-    simplex.build(getStartPoint());\n-    simplex.evaluate(evalFunc, comparator);\n-    PointValuePair[] previous = null;\n-    int iteration = 0;\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n     final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n+    int iter = 0;\n     while (true) {\n-        if (iteration > 0) {\n-            boolean converged = true;\n-            for (int i = 0; i < simplex.getSize(); i++) {\n-                PointValuePair prev = previous[i];\n-                converged = converged && checker.converged(iteration, prev, simplex.getPoint(i));\n-            }\n-            if (converged) {\n-                // We have found an optimum.\n-                return simplex.getPoint(0);\n+        ++iter;\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        // We still need to search.\n-        previous = simplex.getPoints();\n-        simplex.iterate(evalFunc, comparator);\n-        ++iteration;\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n+            }\n+        }\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n+        }\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n+            }\n+        }\n     }\n }\n--- org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizer.java@doOptimize\n@@ -1,76 +1,79 @@\n @Override\n-public PointVectorValuePair doOptimize() {\n+protected PointValuePair doOptimize() {\n     checkParameters();\n-    final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n-    // Computation will be useless without a checker (see \"for-loop\").\n-    if (checker == null) {\n-        throw new NullArgumentException();\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n     }\n-    final double[] targetValues = getTarget();\n-    // Number of observed data.\n-    final int nR = targetValues.length;\n-    final RealMatrix weightMatrix = getWeight();\n-    // Diagonal of the weight matrix.\n-    final double[] residualsWeights = new double[nR];\n-    for (int i = 0; i < nR; i++) {\n-        residualsWeights[i] = weightMatrix.getEntry(i, i);\n-    }\n-    final double[] currentPoint = getStartPoint();\n-    final int nC = currentPoint.length;\n-    // iterate until convergence is reached\n-    PointVectorValuePair current = null;\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n     int iter = 0;\n-    for (boolean converged = false; !converged; ) {\n+    while (true) {\n         ++iter;\n-        // evaluate the objective function and its jacobian\n-        PointVectorValuePair previous = current;\n-        // Value of the objective function at \"currentPoint\".\n-        final double[] currentObjective = computeObjectiveValue(currentPoint);\n-        final double[] currentResiduals = computeResiduals(currentObjective);\n-        final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint);\n-        current = new PointVectorValuePair(currentPoint, currentObjective);\n-        // build the linear problem\n-        final double[] b = new double[nC];\n-        final double[][] a = new double[nC][nC];\n-        for (int i = 0; i < nR; ++i) {\n-            final double[] grad = weightedJacobian.getRow(i);\n-            final double weight = residualsWeights[i];\n-            final double residual = currentResiduals[i];\n-            // compute the normal equation\n-            final double wr = weight * residual;\n-            for (int j = 0; j < nC; ++j) {\n-                b[j] += wr * grad[j];\n-            }\n-            // build the contribution matrix for measurement i\n-            for (int k = 0; k < nC; ++k) {\n-                double[] ak = a[k];\n-                double wgk = weight * grad[k];\n-                for (int l = 0; l < nC; ++l) {\n-                    ak[l] += wgk * grad[l];\n-                }\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        try {\n-            // solve the linearized least squares problem\n-            RealMatrix mA = new BlockRealMatrix(a);\n-            DecompositionSolver solver = useLU ? new LUDecomposition(mA).getSolver() : new QRDecomposition(mA).getSolver();\n-            final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray();\n-            // update the estimated parameters\n-            for (int i = 0; i < nC; ++i) {\n-                currentPoint[i] += dX[i];\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n             }\n-        } catch (SingularMatrixException e) {\n-            throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM);\n         }\n-        // Check convergence.\n-        if (previous != null) {\n-            converged = checker.converged(iter, previous, current);\n-            if (converged) {\n-                setCost(computeCost(currentResiduals));\n-                return current;\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n+        }\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n     }\n-    // Must never happen.\n-    throw new MathInternalError();\n }\n--- org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizer.java@doOptimize\n+++ org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizer.java@doOptimize\n@@ -1,219 +1,78 @@\n @Override\n-protected PointVectorValuePair doOptimize() {\n+protected PointValuePair doOptimize() {\n     checkParameters();\n-    // Number of observed data.\n-    final int nR = getTarget().length;\n-    final double[] currentPoint = getStartPoint();\n-    // Number of parameters.\n-    final int nC = currentPoint.length;\n-    // arrays shared with the other private methods\n-    solvedCols = FastMath.min(nR, nC);\n-    diagR = new double[nC];\n-    jacNorm = new double[nC];\n-    beta = new double[nC];\n-    permutation = new int[nC];\n-    lmDir = new double[nC];\n-    // local point\n-    double delta = 0;\n-    double xNorm = 0;\n-    double[] diag = new double[nC];\n-    double[] oldX = new double[nC];\n-    double[] oldRes = new double[nR];\n-    double[] oldObj = new double[nR];\n-    double[] qtf = new double[nR];\n-    double[] work1 = new double[nC];\n-    double[] work2 = new double[nC];\n-    double[] work3 = new double[nC];\n-    final RealMatrix weightMatrixSqrt = getWeightSquareRoot();\n-    // Evaluate the function at the starting point and calculate its norm.\n-    double[] currentObjective = computeObjectiveValue(currentPoint);\n-    double[] currentResiduals = computeResiduals(currentObjective);\n-    PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);\n-    double currentCost = computeCost(currentResiduals);\n-    // Outer loop.\n-    lmPar = 0;\n-    boolean firstIteration = true;\n+    final GoalType goal = getGoalType();\n+    final double[] guess = getStartPoint();\n+    final int n = guess.length;\n+    final double[][] direc = new double[n][n];\n+    for (int i = 0; i < n; i++) {\n+        direc[i][i] = 1;\n+    }\n+    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();\n+    double[] x = guess;\n+    double fVal = computeObjectiveValue(x);\n+    double[] x1 = x.clone();\n     int iter = 0;\n-    final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();\n     while (true) {\n         ++iter;\n-        final PointVectorValuePair previous = current;\n-        // QR decomposition of the jacobian matrix\n-        qrDecomposition(computeWeightedJacobian(currentPoint));\n-        weightedResidual = weightMatrixSqrt.operate(currentResiduals);\n-        for (int i = 0; i < nR; i++) {\n-            qtf[i] = weightedResidual[i];\n-        }\n-        // compute Qt.res\n-        qTy(qtf);\n-        // now we don't need Q anymore,\n-        // so let jacobian contain the R matrix with its diagonal elements\n-        for (int k = 0; k < solvedCols; ++k) {\n-            int pk = permutation[k];\n-            weightedJacobian[k][pk] = diagR[pk];\n-        }\n-        if (firstIteration) {\n-            // scale the point according to the norms of the columns\n-            // of the initial jacobian\n-            xNorm = 0;\n-            for (int k = 0; k < nC; ++k) {\n-                double dk = jacNorm[k];\n-                if (dk == 0) {\n-                    dk = 1.0;\n-                }\n-                double xk = dk * currentPoint[k];\n-                xNorm += xk * xk;\n-                diag[k] = dk;\n-            }\n-            xNorm = FastMath.sqrt(xNorm);\n-            // initialize the step bound delta\n-            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\n-        }\n-        // check orthogonality between function vector and jacobian columns\n-        double maxCosine = 0;\n-        if (currentCost != 0) {\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                double s = jacNorm[pj];\n-                if (s != 0) {\n-                    double sum = 0;\n-                    for (int i = 0; i <= j; ++i) {\n-                        sum += weightedJacobian[i][pj] * qtf[i];\n-                    }\n-                    maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));\n-                }\n+        double fX = fVal;\n+        double fX2 = 0;\n+        double delta = 0;\n+        int bigInd = 0;\n+        double alphaMin = 0;\n+        for (int i = 0; i < n; i++) {\n+            final double[] d = MathArrays.copyOf(direc[i]);\n+            fX2 = fVal;\n+            final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+            fVal = optimum.getValue();\n+            alphaMin = optimum.getPoint();\n+            final double[][] result = newPointAndDirection(x, d, alphaMin);\n+            x = result[0];\n+            if ((fX2 - fVal) > delta) {\n+                delta = fX2 - fVal;\n+                bigInd = i;\n             }\n         }\n-        if (maxCosine <= orthoTolerance) {\n-            // Convergence has been reached.\n-            setCost(currentCost);\n-            return current;\n+        // Default convergence check.\n+        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);\n+        final PointValuePair previous = new PointValuePair(x1, fX);\n+        final PointValuePair current = new PointValuePair(x, fVal);\n+        if (!stop) {\n+            // User-defined stopping criteria.\n+            if (checker != null) {\n+                stop = checker.converged(iter, previous, current);\n+            }\n         }\n-        // rescale if necessary\n-        for (int j = 0; j < nC; ++j) {\n-            diag[j] = FastMath.max(diag[j], jacNorm[j]);\n+        if (stop) {\n+            if (goal == GoalType.MINIMIZE) {\n+                return (fVal < fX) ? current : previous;\n+            } else {\n+                return (fVal > fX) ? current : previous;\n+            }\n         }\n-        // Inner loop.\n-        for (double ratio = 0; ratio < 1.0e-4; ) {\n-            // save the state\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                oldX[pj] = currentPoint[pj];\n-            }\n-            final double previousCost = currentCost;\n-            double[] tmpVec = weightedResidual;\n-            weightedResidual = oldRes;\n-            oldRes = tmpVec;\n-            tmpVec = currentObjective;\n-            currentObjective = oldObj;\n-            oldObj = tmpVec;\n-            // determine the Levenberg-Marquardt parameter\n-            determineLMParameter(qtf, delta, diag, work1, work2, work3);\n-            // compute the new point and the norm of the evolution direction\n-            double lmNorm = 0;\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                lmDir[pj] = -lmDir[pj];\n-                currentPoint[pj] = oldX[pj] + lmDir[pj];\n-                double s = diag[pj] * lmDir[pj];\n-                lmNorm += s * s;\n-            }\n-            lmNorm = FastMath.sqrt(lmNorm);\n-            // on the first iteration, adjust the initial step bound.\n-            if (firstIteration) {\n-                delta = FastMath.min(delta, lmNorm);\n-            }\n-            // Evaluate the function at x + p and calculate its norm.\n-            currentObjective = computeObjectiveValue(currentPoint);\n-            currentResiduals = computeResiduals(currentObjective);\n-            current = new PointVectorValuePair(currentPoint, currentObjective);\n-            currentCost = computeCost(currentResiduals);\n-            // compute the scaled actual reduction\n-            double actRed = -1.0;\n-            if (0.1 * currentCost < previousCost) {\n-                double r = currentCost / previousCost;\n-                actRed = 1.0 - r * r;\n-            }\n-            // compute the scaled predicted reduction\n-            // and the scaled directional derivative\n-            for (int j = 0; j < solvedCols; ++j) {\n-                int pj = permutation[j];\n-                double dirJ = lmDir[pj];\n-                work1[j] = 0;\n-                for (int i = 0; i <= j; ++i) {\n-                    work1[i] += weightedJacobian[i][pj] * dirJ;\n-                }\n-            }\n-            double coeff1 = 0;\n-            for (int j = 0; j < solvedCols; ++j) {\n-                coeff1 += work1[j] * work1[j];\n-            }\n-            double pc2 = previousCost * previousCost;\n-            coeff1 = coeff1 / pc2;\n-            double coeff2 = lmPar * lmNorm * lmNorm / pc2;\n-            double preRed = coeff1 + 2 * coeff2;\n-            double dirDer = -(coeff1 + coeff2);\n-            // ratio of the actual to the predicted reduction\n-            ratio = (preRed == 0) ? 0 : (actRed / preRed);\n-            // update the step bound\n-            if (ratio <= 0.25) {\n-                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;\n-                if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {\n-                    tmp = 0.1;\n-                }\n-                delta = tmp * FastMath.min(delta, 10.0 * lmNorm);\n-                lmPar /= tmp;\n-            } else if ((lmPar == 0) || (ratio >= 0.75)) {\n-                delta = 2 * lmNorm;\n-                lmPar *= 0.5;\n-            }\n-            // test for successful iteration.\n-            if (ratio >= 1.0e-4) {\n-                // successful iteration, update the norm\n-                firstIteration = false;\n-                xNorm = 0;\n-                for (int k = 0; k < nC; ++k) {\n-                    double xK = diag[k] * currentPoint[k];\n-                    xNorm += xK * xK;\n-                }\n-                xNorm = FastMath.sqrt(xNorm);\n-                // tests for convergence.\n-                if (checker != null) {\n-                    // we use the vectorial convergence checker\n-                    if (checker.converged(iter, previous, current)) {\n-                        setCost(currentCost);\n-                        return current;\n-                    }\n-                }\n-            } else {\n-                // failed iteration, reset the previous values\n-                currentCost = previousCost;\n-                for (int j = 0; j < solvedCols; ++j) {\n-                    int pj = permutation[j];\n-                    currentPoint[pj] = oldX[pj];\n-                }\n-                tmpVec = weightedResidual;\n-                weightedResidual = oldRes;\n-                oldRes = tmpVec;\n-                tmpVec = currentObjective;\n-                currentObjective = oldObj;\n-                oldObj = tmpVec;\n-                // Reset \"current\" to previous values.\n-                current = new PointVectorValuePair(currentPoint, currentObjective);\n-            }\n-            // Default convergence criteria.\n-            if ((FastMath.abs(actRed) <= costRelativeTolerance && preRed <= costRelativeTolerance && ratio <= 2.0) || delta <= parRelativeTolerance * xNorm) {\n-                setCost(currentCost);\n-                return current;\n-            }\n-            // tests for termination and stringent tolerances\n-            // (2.2204e-16 is the machine epsilon for IEEE754)\n-            if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n-                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);\n-            } else if (delta <= 2.2204e-16 * xNorm) {\n-                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);\n-            } else if (maxCosine <= 2.2204e-16) {\n-                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);\n+        final double[] d = new double[n];\n+        final double[] x2 = new double[n];\n+        for (int i = 0; i < n; i++) {\n+            d[i] = x[i] - x1[i];\n+            x2[i] = 2 * x[i] - x1[i];\n+        }\n+        x1 = x.clone();\n+        fX2 = computeObjectiveValue(x2);\n+        if (fX > fX2) {\n+            double t = 2 * (fX + fX2 - 2 * fVal);\n+            double temp = fX - fVal - delta;\n+            t *= temp * temp;\n+            temp = fX - fX2;\n+            t -= delta * temp * temp;\n+            if (t < 0.0) {\n+                final UnivariatePointValuePair optimum = lineSearch.search(x, d); // Changed line.search to lineSearch.search\n+                fVal = optimum.getValue();\n+                alphaMin = optimum.getPoint();\n+                final double[][] result = newPointAndDirection(x, d, alphaMin);\n+                x = result[0];\n+                final int lastInd = n - 1;\n+                direc[bigInd] = direc[lastInd];\n+                direc[lastInd] = result[1];\n             }\n         }\n     }\n", "finish_reason": "stop", "valid": false, "num": 1}]